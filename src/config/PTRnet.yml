# PTRnet - nucleotide level model

# Training
epochs: 200
save_freq: 1
val_freq: 1
warmup: 0
batch_size: 64
#batch_size: 64  # for pretrain
num_workers: 1
masked_tokens: 0.15  # % of randomly masked tokens during pretraining


# Model
model: "ptrnet"
dim_embedding_tissue: 64  # max 29 tissues
dim_embedding_token: 64  # 64 codons or 4 nucleotides/
predictor_hidden_dim: 32  # hidden size of the output layer
predictor_dropout: 0.3  # dropout rate of the output layer

base_channels: 64
num_blocks: 10

num_layers: 4  # number of layers in the model, more than 8 not possible for seq len 2700
dropout: 0.1  # dropout rate of the model


# Data
align_aug: True  # if True, will align the sequences to the AUG start codon (no sequence reversal possible)
random_reverse: False
frequency_features: False
scale_targets: False  # only works for binary_class == False
seq_only: False
seq_encoding: "ohe" # ["embedding", "ohe" "word2vec"]
embedding_max_norm: 2
grad_clip_norm: 0.5  # 0 or negative â†’ no clipping


# Optimizer
optimizer:
  name: adam  # sgd, adam, ranger
  lr: 0.001
#  lr: 0.0001  # for pretrain
  weight_decay: 0.01


# Scheduler (Cosine Annealing Warm Restarts)
lr_scheduler:
  enable: False
  warmup: 10
#  warmup: 20  # for pretrain
  reset_epochs: 5
  T_mult: 2
  min_lr: 1e-7