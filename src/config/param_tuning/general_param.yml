#batch_size: [64, 64, 64]
random_reverse: [True, False]
dim_embedding: [16, 32, 64, 128]
predictor_hidden: [32, 64, 128]
#predictor_dropout: [0.0, 0.1, 0.3]
weight_decay: [0.1, 0.01, 0.001, 0.0001]
lr:
  min: 1e-5
  max: 1e-2