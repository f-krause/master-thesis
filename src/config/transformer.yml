#subproject: "dev_transformer/v3_full_seq_length_100"
subproject: "dev_transformer/delete_me"

# Training
gpu_id: 0
epochs: 50
save_freq: 10
val_freq: 1
warmup: 0
batch_size: 32
num_workers: 1

# Model
model: "transformer"
dim_embedding_token: 32  # Embedding dimension for tokens
tissue_embedding_dim: 32  # Embedding dimension for tissues
predictor_hidden_dim: 64
predictor_dropout: 0.1

# Transformer Config
num_heads: 8
num_layers: 6
dim_feedforward: 512
dropout: 0.1
activation: "gelu"

# Optimizer
optimizer:
  name: adam
  lr: 0.0001
  weight_decay: 0.1  # ranger only
