#subproject: "dev_transformer/v3_full_seq_length_100"
subproject: "dev_transformer/delete_me"

# Training
epochs: 100
save_freq: 25
val_freq: 10
warmup: 0
batch_size: 32
num_workers: 1

# Model
model: "transformer"
dim_embedding_token: 32  # Embedding dimension for tokens
tissue_embedding_dim: 32  # Embedding dimension for tissues
out_hidden_size: 64

# Transformer Config
num_heads: 8
num_layers: 6
dim_feedforward: 256
dropout: 0.1
activation: "gelu"

# Optimizer
optimizer:
  name: adam
  lr: 0.0001
